## ğŸ“– TTS Dataset Pipeline

A simple three-step pipeline for building paired (audio, text) datasets for TTS / ASR tasks.

### Core workflow:

1. VAD Splitting â€“ use Silero VAD
 to segment long audio into short utterances.

2. Whisper Transcription â€“ use OpenAI Whisper
 to generate transcriptions.

3. Upload to Hugging Face Hub â€“ package the dataset into standard ğŸ¤— Datasets
 format.

The final dataset structure:

```bash
my_dataset/
  â”œâ”€â”€ data/
  â”‚    â”œâ”€â”€ chunk_0001.wav
  â”‚    â”œâ”€â”€ chunk_0002.wav
  â”‚    â””â”€â”€ ...
  â””â”€â”€ metadata.csv

```
```metadata.csv``` example:

```bash
file,text
data/chunk_0001.wav,This is the first sentence.
data/chunk_0002.wav,This is the second one.
...

```

### ğŸš€ Quickstart
1. Install dependencies (using uv)


```bash
uv pip install -r pyproject.toml
or
uv sync
```
Main dependencies:
- torch, torchaudio

- openai-whisper

- datasets, huggingface_hub

2. VAD-based audio splitting
```bash
python vad_split.py --input demo.wma --output my_dataset
```
This will create segmented audio chunks under my_dataset/data/

3. Whisper transcription
```bash
python transcribe.py --dataset my_dataset --model_size medium --lang zh

```
This generates metadata.csv inside my_dataset/, containing paired (file, text) entries.
4. Upload to Hugging Face Hub
```bash
python upload_hf.py --dataset my_dataset --repo your-username/your-dataset-name

```
You will be prompted for your Hugging Face token.

## ğŸ“‚ Project Structure

```bash
project/
â”‚â”€â”€ pyproject.toml     # uv dependency management
â”‚â”€â”€ vad_split.py       # Step 1: VAD splitting
â”‚â”€â”€ transcribe.py      # Step 2: Whisper transcription
â”‚â”€â”€ upload_hf.py       # Step 3: Upload to Hugging Face
â”‚â”€â”€ my_dataset/        # Output dataset
â”‚    â”œâ”€â”€ data/
â”‚    â””â”€â”€ metadata.csv


```
## ğŸ“ License

MIT License